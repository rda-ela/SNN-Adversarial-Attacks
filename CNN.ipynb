{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport foolbox as fb\nimport foolbox.attacks as fa\nfrom foolbox import PyTorchModel, accuracy, samples\n\nimport numpy as np\n\nimport statistics","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 1\nbatchsize = 64\nlearning_rate = 0.001\nmomentum = 0.9\nlog_interval = 100","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.Resize(32),\n     transforms.ToTensor(),\n     torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n\ntrainset = torchvision.datasets.MNIST(root='./data', train=True,\n                                        download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n                                          shuffle=True)\n\ntestset = torchvision.datasets.MNIST(root='./data', train=False,\n                                       download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n                                         shuffle=False)","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112d9585966144fb8c06ed40b3959ddc"}},"metadata":{}},{"output_type":"stream","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0661f12ed9b540f487528460618cc6d4"}},"metadata":{}},{"output_type":"stream","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088d7934159e43cd84b384951d59e748"}},"metadata":{}},{"output_type":"stream","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47687ca48e84fb2b4998679b57165f0"}},"metadata":{}},{"output_type":"stream","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729141890/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5,stride=1)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1)\n        self.fc1 = nn.Linear(120,84)\n        self.fc2 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n        x = F.relu(self.conv3(x))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","execution_count":5,"outputs":[{"output_type":"stream","text":"\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"network = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(network.parameters(), lr=learning_rate)       \n\ntrain_losses = []\ntrain_counter = []\ntest_losses = []\ntest_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n\ndef train(epoch):\n  network.train()\n  for batch_idx, (data, target) in enumerate(train_loader):\n    optimizer.zero_grad()\n    output = network(data)\n    loss = criterion(output, target)\n    loss.backward()\n    optimizer.step()\n    if batch_idx % log_interval == 0:\n      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n        epoch, batch_idx * len(data), len(train_loader.dataset),\n        100. * batch_idx / len(train_loader), loss.item()))\n      train_losses.append(loss.item())\n      train_counter.append(\n        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n\ndef test():\n  network.eval()\n  test_loss = 0\n  correct = 0\n  with torch.no_grad():\n    for data, target in test_loader:\n      output = network(data)\n      test_loss += criterion(output, target).item()\n      pred = output.data.max(1, keepdim=True)[1]\n      correct += pred.eq(target.data.view_as(pred)).sum()\n  test_loss /= len(test_loader.dataset)\n  test_losses.append(test_loss)\n  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n    test_loss, correct, len(test_loader.dataset),\n    100. * correct / len(test_loader.dataset)))\n\nprint(\" \")\nfor epoch in range(1, n_epochs + 1):\n  train(epoch)\n  test()        ","execution_count":6,"outputs":[{"output_type":"stream","text":" \nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.302818\nTrain Epoch: 1 [6400/60000 (11%)]\tLoss: 0.293363\nTrain Epoch: 1 [12800/60000 (21%)]\tLoss: 0.219899\nTrain Epoch: 1 [19200/60000 (32%)]\tLoss: 0.080069\nTrain Epoch: 1 [25600/60000 (43%)]\tLoss: 0.188698\nTrain Epoch: 1 [32000/60000 (53%)]\tLoss: 0.149624\nTrain Epoch: 1 [38400/60000 (64%)]\tLoss: 0.040187\nTrain Epoch: 1 [44800/60000 (75%)]\tLoss: 0.187087\nTrain Epoch: 1 [51200/60000 (85%)]\tLoss: 0.067371\nTrain Epoch: 1 [57600/60000 (96%)]\tLoss: 0.074860\n\nTest set: Avg. loss: 0.0013, Accuracy: 9717/10000 (97%)\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This function does the same work as foolbox, it allows us to compare the values of foolbox\n#It's only used to check if there is no issues with the model given to foolbox\n\ndef benchmark():   \n    listeimg = []\n    listeadv = []\n    for i in range(len(images)):\n      imaj = images[i]\n      img = imaj\n      listeimg.append(img)\n      tempadvlist = []\n      for e in range(len(epsilons)):\n        iadvs = advs[e][i]\n        adv = iadvs\n        tempadvlist.append(adv)\n      listeadv.append(tempadvlist)\n\n    results = []\n\n    model.eval()\n    for e in range(len(epsilons)):\n      tempepsilons = []\n      for i in range(len(listeadv)):\n        imgadvtest = listeadv[i][e]\n        lb = labels[i].item()\n        with torch.no_grad():\n          output = model(imgadvtest.unsqueeze(0))\n        pred = output.data.max(1, keepdim=True)[1][0].item() \n        prob = torch.nn.functional.softmax(output, dim=1)\n        top_p, top_class = prob.topk(1, dim = 1)\n        if(str(lb)==str(pred)):\n          tempepsilons.append(\"FALSE\")\n        else:\n          tempepsilons.append(\"TRUE\")\n      results.append(tempepsilons)\n\n    for i in range(len(results)):\n        v = 0\n        for e in range(len(results[0])):\n            if results[i][e] == \"FALSE\":\n                v = v+1\n        print(\"eps: \"+ str(epsilons[i]), end=' | ')\n        print(\"pred en %: \" + str(float(v/len(results[0]))*100)) \n        print(\"\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adv_loader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n                                         shuffle=False)\n\nexamples = enumerate(adv_loader)\nbatch_idx, (images, labels) = next(examples)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = network\nprint(model)","execution_count":9,"outputs":[{"output_type":"stream","text":"Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=120, out_features=84, bias=True)\n  (fc2): Linear(in_features=84, out_features=10, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n\nprint(\" \")\nprint(\"accuracy\", end=' | ')\nprint(accuracy(fmodel, images, labels))\nprint(\"\")\n\nattacks = [fb.attacks.PGD()]\n\nepsilons = [\n    0.0,\n    0.1,\n    0.2,\n    0.3,\n    0.4,\n    0.5,\n    0.6,\n    0.7,\n    0.8,\n    0.9,\n    1.0,\n    1.1,\n    1.2,\n    1.3,\n    1.4,\n    1.5,\n    1.6,\n    1.7,\n    1.8,\n    1.9,\n    2.0,\n]\n\nprint(\"epsilons\")\nprint(epsilons)\nprint(\"\")\n","execution_count":10,"outputs":[{"output_type":"stream","text":" \naccuracy | 0.984375\n\nepsilons\n[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbyat = []\nfulatac = []\nfor i, attack in enumerate(attacks):\n    _, advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n    benchmark()\n    atacc = []\n    robust_accuracy = 1 - success.float().mean(axis=-1)\n    for eps, acc in zip(epsilons, robust_accuracy):\n        print(attack, eps, acc.item())\n        atacc.append(acc.item())\n    print(\" \")\n    fulatac.append(atacc)\n    lfull = []\n    for e in range(len(epsilons)):\n        l = []\n        for i in range(len(images)):\n            perturbation = advs[e][i][0].numpy() - images[i][0].numpy()\n            l.append(float(format(np.linalg.norm(perturbation.flatten()))))\n        lfull.append(statistics.mean(l))\n    lbyat.append(lfull)","execution_count":11,"outputs":[{"output_type":"stream","text":"eps: 0.0 | pred en %: 98.4375\n\neps: 0.1 | pred en %: 98.4375\n\neps: 0.2 | pred en %: 96.875\n\neps: 0.3 | pred en %: 96.875\n\neps: 0.4 | pred en %: 93.75\n\neps: 0.5 | pred en %: 87.5\n\neps: 0.6 | pred en %: 70.3125\n\neps: 0.7 | pred en %: 35.9375\n\neps: 0.8 | pred en %: 9.375\n\neps: 0.9 | pred en %: 7.8125\n\neps: 1.0 | pred en %: 3.125\n\neps: 1.1 | pred en %: 1.5625\n\neps: 1.2 | pred en %: 1.5625\n\neps: 1.3 | pred en %: 0.0\n\neps: 1.4 | pred en %: 0.0\n\neps: 1.5 | pred en %: 0.0\n\neps: 1.6 | pred en %: 0.0\n\neps: 1.7 | pred en %: 0.0\n\neps: 1.8 | pred en %: 0.0\n\neps: 1.9 | pred en %: 0.0\n\neps: 2.0 | pred en %: 0.0\n\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.0 0.984375\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.1 0.984375\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.2 0.96875\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.3 0.96875\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.4 0.9375\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.5 0.875\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.6 0.703125\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.7 0.359375\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.8 0.09375\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 0.9 0.078125\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.0 0.03125\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.1 0.015625\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.2 0.015625\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.3 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.4 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.5 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.6 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.7 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.8 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 1.9 0.0\nLinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True) 2.0 0.0\n \n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}